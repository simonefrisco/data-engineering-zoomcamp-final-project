id: 1-upload-data-to-datalake
namespace: dev
description: Download zip file from S3 and create a Delta Table

labels:
  env: dev
  project: debug

variables:
  aws_s3_bucket : s3://kestra-datatalkclub-project

tasks:
  - id: wdir
    type: io.kestra.core.tasks.flows.WorkingDirectory
    tasks:

      - id: downloadFromS3
        type: io.kestra.plugin.aws.s3.Download
        accessKeyId: "{{ secret('AWS_ACCESS_KEY') }}"
        secretKeyId: "{{ secret('AWS_SECRET_KEY') }}"
        region: "{{ secret('AWS_REGION') }}"
        bucket: "kestra-datatalkclub"
        key: "download/direct-messaging.zip"

      - id: unzip
        type: io.kestra.plugin.compress.ArchiveDecompress
        algorithm: ZIP
        from: "{{outputs.downloadFromS3.uri}}"
  
      - id: printFiles
        type: io.kestra.plugin.scripts.python.Script
        runner: PROCESS
        namespaceFiles:
          enabled: true
        script : |
          import os
          def print_files(directory):
              for root, dirs, files in os.walk(directory):
                  for file in files:
                      print(os.path.join(root, file))
          print_files(os.getcwd())

      - id : uploadTable
        type: io.kestra.plugin.scripts.python.Script
        runner: DOCKER
        docker:
          image: ghcr.io/kestra-io/polars:latest
          pullPolicy: IF_NOT_PRESENT
        beforeCommands:
          - "pip install deltalake"
        inputFiles : 
          messages-demo.csv : '{{ outputs.unzip.files["messages-demo.csv"] }}'
          campaigns.csv : '{{ outputs.unzip.files["campaigns.csv"] }}'
          client_first_purchase_date.csv : '{{ outputs.unzip.files["client_first_purchase_date.csv"] }}'
          holidays.csv : '{{ outputs.unzip.files["holidays.csv"] }}'
        script: "{{ render(read('scripts/stage1/import_data.py')) }}"